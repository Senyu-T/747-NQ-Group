{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NQ_bertbilstm_unfreeze.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63df2fe7ac224957b87c2d5bff20e81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ef42b292e7040e0890c206a32a3d804",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b64571a066d94aef8b700d2bf8509718",
              "IPY_MODEL_f73c87de74304fa28feb88f9f7d87d01"
            ]
          }
        },
        "8ef42b292e7040e0890c206a32a3d804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b64571a066d94aef8b700d2bf8509718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc06667f5dd246a29dc0ba9cfaf24f09",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8d0062a3b7241668b0de8bff9cc8146"
          }
        },
        "f73c87de74304fa28feb88f9f7d87d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c58642c4d9f41c590c7b054d1ef4493",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 18.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfe9eb0ffa4e4e899a0f880b8ffa4c90"
          }
        },
        "bc06667f5dd246a29dc0ba9cfaf24f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8d0062a3b7241668b0de8bff9cc8146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c58642c4d9f41c590c7b054d1ef4493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfe9eb0ffa4e4e899a0f880b8ffa4c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0baf83c96a2741f5bbda6cdc5056a379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8dab8433c2454ea8a742fef9e4a6fdea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ce4a10a9f9b43adacc7d836b9960224",
              "IPY_MODEL_4fa9f18f9ade4550aee50bf9b882b069"
            ]
          }
        },
        "8dab8433c2454ea8a742fef9e4a6fdea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ce4a10a9f9b43adacc7d836b9960224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4e01145435f433fbfc798e6c62bde89",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40ecaa9ae90e48f7931b8ca6b581da06"
          }
        },
        "4fa9f18f9ade4550aee50bf9b882b069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_251f705645874657b6649797f7ea486b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:25&lt;00:00, 17.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa5eb0765339451182c20376a18d3b83"
          }
        },
        "d4e01145435f433fbfc798e6c62bde89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40ecaa9ae90e48f7931b8ca6b581da06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "251f705645874657b6649797f7ea486b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa5eb0765339451182c20376a18d3b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGUkMDujkUtz"
      },
      "source": [
        "!git clone https://github.com/Senyu-T/unifiedqa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2kwLxnzEzce"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNlgBI9fGn4X"
      },
      "source": [
        "cd unifiedqa/bart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeGQOSHLk9Pw"
      },
      "source": [
        "!chmod +x download_data.sh; ./download_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-WIxDi3eFfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d00b40c-0e00-4ee4-a872-7965f8208ffc"
      },
      "source": [
        "cd data/natural_questions_with_dpr_para/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/unifiedqa/bart/data/natural_questions_with_dpr_para\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuzI8Be_dOQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685c9fb4-e029-4b20-fcc4-1a49a4ca6e2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LPKS4CYFz9q"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/NQ\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW3AEY24FOXe"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def normalize_answer(s):\n",
        "  def remove_articles(text):\n",
        "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "  def white_space_fix(text):\n",
        "    return ' '.join(text.split())\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return ''.join(ch for ch in text if ch not in exclude)\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def remove_spc_token(s):\n",
        "  s = s.replace(' \\\\\\'\\\\\\'', ' \\'\\'')   # double quotation\n",
        "  s = s.replace('\\\\\\'', '\\'')\n",
        "  s = s.replace(' \\'s', '\\'s')    # 's\n",
        "  s = s.replace(' ,', ',')\n",
        "  return s"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U50Luz_FQU2"
      },
      "source": [
        "# read file, parse into context / question / answer for further data analysis\n",
        "def read_files(file_name):\n",
        "  answers = []\n",
        "  questions = []\n",
        "  contexts = []\n",
        "  with open(file_name, 'rb') as inference_in:\n",
        "    lines = inference_in.readlines()\n",
        "    for i in range(len(lines)):\n",
        "      sep = str(lines[i]).split('\\\\n') \n",
        "      questions.append(sep[0][2:-1])\n",
        "      ans = (sep[1].split('\\\\t')[-1]).lower()\n",
        "      ans = normalize_answer(remove_spc_token(ans))  # normalize answers\n",
        "      answers.append(ans)\n",
        "      contexts.append(sep[1].split('\\\\t')[0])\n",
        "  return answers, questions, contexts"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9NjH_9DGToh"
      },
      "source": [
        "tr_answers, tr_questions, tr_contexts = read_files(\"/content/unifiedqa/bart/data/natural_questions_with_dpr_para/train.tsv\")\n",
        "val_answers, val_questions, val_contexts = read_files(\"/content/unifiedqa/bart/data/natural_questions_with_dpr_para/dev.tsv\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEeejJNDGnON"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWl1SsGxHs2H"
      },
      "source": [
        "import torch\n",
        "import torch.optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel, BertTokenizerFast, BertTokenizer, AutoTokenizer, BertModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwbIIL6vGDM9"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self,embedding_dim, hidden_dim, num_layers, num_classes):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
        "                    hidden_size=hidden_dim,\n",
        "                    num_layers=num_layers,\n",
        "                    batch_first=False,\n",
        "                    bidirectional=True)\n",
        "        self.fc1 = torch.nn.Linear(2*hidden_dim, hidden_dim)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(hidden_dim, num_classes)\n",
        "    \n",
        "    \n",
        "    def forward(self, embeddings):\n",
        "        self.lstm.flatten_parameters()\n",
        "        lstm_output, _ = self.lstm(embeddings)\n",
        "        output = lstm_output[:,-1,:]\n",
        "        output = self.fc1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "        return output\n",
        "\n",
        "class BertBiLSTM(nn.Module):\n",
        "    def __init__(self, num_layers, num_classes, embedding_dim = 768, hidden_dim=128):\n",
        "        super(BertBiLSTM, self).__init__()\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        for param in self.bert.parameters():\n",
        "          param.requires_grad = False\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.classifier = BiLSTM(self.embedding_dim, hidden_dim, num_layers, num_classes)\n",
        "       \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        text_embeddings = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_embeddings = text_embeddings[0]\n",
        "        \n",
        "        output = self.classifier(text_embeddings)\n",
        "        return output"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OWAS6IXGEib"
      },
      "source": [
        "MAX_LEN = 64\n",
        "\n",
        "def preprocessing_for_bert(tokenizer, sentences):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    num_sentences = len(sentences)\n",
        "\n",
        "    for i, sent in enumerate(sentences):\n",
        "      encoded_sent = tokenizer.encode_plus(text=sent, \n",
        "                          add_special_tokens=True,        \n",
        "                          max_length=MAX_LEN,               \n",
        "                          padding='max_length',         \n",
        "                          return_attention_mask=True, \n",
        "                          truncation=True)     \n",
        "      input_ids.append(encoded_sent.get('input_ids'))\n",
        "      attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    return input_ids, attention_masks\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxhuePqEGGGH"
      },
      "source": [
        "def get_data(file_path, tsv_file, tokenizer, save_location, label2index=None, index2label=None):\n",
        "    answers, questions, contexts = read_files(file_path)\n",
        "\n",
        "    tsv_file = open(tsv_file)\n",
        "    read_tsv = csv.reader(tsv_file)\n",
        "    labels = [row[0] for row in read_tsv]\n",
        "\n",
        "    if label2index is None:\n",
        "      label_set = set(labels)\n",
        "      label2index = {label:index for index, label in enumerate(label_set)}\n",
        "      index2label = {index:label for index, label in enumerate(label_set)}\n",
        "\n",
        "    labels = [label2index[label] for label in labels]\n",
        "\n",
        "    input_ids, attention_masks = preprocessing_for_bert(tokenizer, questions)\n",
        "    np.savez(save_location, input_ids=input_ids, attention_masks=attention_masks, labels=labels, label2index=label2index, index2label=index2label)\n",
        "    return len(label2index)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhYoOeCWGId_"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeoKRsbbIVI8"
      },
      "source": [
        "train_path = \"/content/unifiedqa/bart/data/natural_questions_with_dpr_para/train.tsv\"\n",
        "val_path = \"/content/unifiedqa/bart/data/natural_questions_with_dpr_para/dev.tsv\"\n",
        "tr_tags = \"/content/drive/MyDrive/NQ/data/answer_tags/train_soft_tag.tsv\"\n",
        "val_tags = \"/content/drive/MyDrive/NQ/data/answer_tags/dev_soft_tag.tsv\""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmNG1t7IJHly"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/NQ\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc-ew8t4JKr8"
      },
      "source": [
        "num_classes = get_data(train_path, tr_tags, tokenizer, \"data/tr_tokenized.npz\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsyVye7NJctJ"
      },
      "source": [
        "num_classes = get_data(val_path, val_tags, tokenizer, \"data/val_tokenized.npz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tM1RG4CKCHu"
      },
      "source": [
        "def load_dataset(location):\n",
        "    data = dict(np.load(location,allow_pickle=True))\n",
        "    for key, elem in data.items():\n",
        "      if key=='label2index' or key=='index2label':\n",
        "        continue\n",
        "      data[key] = torch.tensor(elem)\n",
        "    dataset = TensorDataset(data['input_ids'].squeeze(), data['attention_masks'].squeeze(), data['labels'])\n",
        "    return dataset "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2JVDEP0KFhn"
      },
      "source": [
        "train_path = \"data/tr_tokenized.npz\"\n",
        "train_dataset = load_dataset(train_path)\n",
        "val_path = \"data/val_tokenized.npz\"\n",
        "val_dataset = load_dataset(val_path)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-boZpZ-2Kbpv"
      },
      "source": [
        "def evaluate(network, loader, loss_fn, data_size):\n",
        "    loss = 0.0\n",
        "    acc = 0.0\n",
        "    with torch.no_grad():\n",
        "      for i, (input_ids, masks, labels) in tqdm(enumerate(loader),total=len(loader),position=0, leave=True):\n",
        "          input_ids = input_ids.cuda()\n",
        "          masks = masks.cuda()\n",
        "          labels = labels.cuda()\n",
        "            \n",
        "          output = network(input_ids, masks)\n",
        "          loss += loss_fn(output,labels)\n",
        "          preds = torch.argmax(output,dim=1)\n",
        "          #output = network(input_ids, masks, labels=labels)\n",
        "          #preds = torch.argmax(output.logits, dim=1)\n",
        "          #loss = output.loss\n",
        "\n",
        "          acc += torch.eq(preds, labels).sum().item()\n",
        "    return loss.item() / data_size, acc / data_size"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oqJBoupKc8Q"
      },
      "source": [
        "def train(directory, network, loss_fn, train_dataset, test_dataset, optimizer, scheduler, batch_size, num_epochs, verbose=True, val_freq=5):\n",
        "    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
        "    \n",
        "    train_loss, train_acc = torch.zeros(num_epochs), torch.zeros(num_epochs)\n",
        "    test_loss, test_acc = torch.zeros(num_epochs//val_freq + 1), torch.zeros(num_epochs//val_freq + 1)\n",
        "    val_best_acc, train_best_acc = 0.0, 0.0\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch % val_freq == 0:\n",
        "          network.eval()\n",
        "          idx = epoch//val_freq\n",
        "          test_loss[idx], test_acc[idx] = evaluate(network, val_dataloader, loss_fn, len(test_dataset))\n",
        "          if test_acc[idx] > val_best_acc:\n",
        "            val_best_acc = test_acc[idx]\n",
        "            torch.save(network.state_dict(), f\"{directory}/snapshot_val_best\")\n",
        "          if verbose:\n",
        "            print(f\"epoch:{epoch:3d}, test_loss: {test_loss[idx]:3.6f}, test_acc: {test_acc[idx]:3.5f}\")\n",
        "\n",
        "        network.train()\n",
        "        train_epoch_loss, train_epoch_acc = 0.0, 0.0\n",
        "        for i, (input_ids, masks, labels) in tqdm(enumerate(train_dataloader), total=len(train_dataloader), position=0, leave=True):\n",
        "            input_ids = input_ids.cuda()\n",
        "            masks = masks.cuda()\n",
        "            labels = labels.cuda()              \n",
        "            optimizer.zero_grad() \n",
        "            \n",
        "            output = network(input_ids, masks)\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            train_epoch_acc += torch.eq(pred, labels).sum().item()\n",
        "            loss = loss_fn(output,labels)/batch_size\n",
        "\n",
        "            # commented lines are codes for BertSeqeucen\n",
        "            #output = network(input_ids, masks, labels=labels)       \n",
        "            #pred = torch.argmax(output.logits, dim=1)\n",
        "            #loss = output.loss\n",
        "            train_epoch_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_acc[epoch] = train_epoch_acc / len(train_dataset)\n",
        "        train_loss[epoch] = train_epoch_loss / len(train_dataloader)\n",
        "        print(f\"train_loss:{train_loss[epoch]:.6f}, train_acc:{train_acc[epoch]:.6f}\")\n",
        "        if (train_acc[epoch] > train_best_acc):\n",
        "          train_best_acc = train_acc[epoch]\n",
        "          torch.save(network.state_dict(), f\"{directory}/snapshot_train_best\")\n",
        "\n",
        "        scheduler.step(test_acc[epoch//val_freq])\n",
        "\n",
        "    network.eval()   \n",
        "    test_loss[-1], test_acc[-1] = evaluate(network, val_dataloader, loss_fn, len(test_dataset))    \n",
        "    torch.save(train_loss, f\"{directory}/train_loss\")\n",
        "    torch.save(test_loss, f\"{directory}/test_loss\")\n",
        "    torch.save(train_acc, f\"{directory}/train_acc\")\n",
        "    torch.save(test_acc, f\"{directory}/test_acc\")\n",
        "    torch.save(network.state_dict(), f\"{directory}/snapshot_final\")\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA9kqy7dKfuG"
      },
      "source": [
        "def get_path(loss, opt, lr, batch_size, epoch):\n",
        "    return f\"{PATH}/lr_{lr}_bs_{batch_size}_loss_{loss}_epoch_{epoch}_opt_{opt}\""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIyrsQftKh0w"
      },
      "source": [
        "loss = 'ce'\n",
        "opt = 'adam'\n",
        "batch_size = 32\n",
        "lr = 1e-5\n",
        "num_epochs = 50"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G85wXkN7KjB8"
      },
      "source": [
        "PATH = \"bert_bilstm_classifier\"\n",
        "directory = f\"{get_path(loss, opt, lr, batch_size, num_epochs)}\"\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "torch.manual_seed(11747)\n",
        "num_layers = 2"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "63df2fe7ac224957b87c2d5bff20e81e",
            "8ef42b292e7040e0890c206a32a3d804",
            "b64571a066d94aef8b700d2bf8509718",
            "f73c87de74304fa28feb88f9f7d87d01",
            "bc06667f5dd246a29dc0ba9cfaf24f09",
            "e8d0062a3b7241668b0de8bff9cc8146",
            "4c58642c4d9f41c590c7b054d1ef4493",
            "dfe9eb0ffa4e4e899a0f880b8ffa4c90",
            "0baf83c96a2741f5bbda6cdc5056a379",
            "8dab8433c2454ea8a742fef9e4a6fdea",
            "2ce4a10a9f9b43adacc7d836b9960224",
            "4fa9f18f9ade4550aee50bf9b882b069",
            "d4e01145435f433fbfc798e6c62bde89",
            "40ecaa9ae90e48f7931b8ca6b581da06",
            "251f705645874657b6649797f7ea486b",
            "fa5eb0765339451182c20376a18d3b83"
          ]
        },
        "id": "7tqUcRLkKkrx",
        "outputId": "02da33c8-06d2-4440-e7bf-359d0b3da2ec"
      },
      "source": [
        "network = BertBiLSTM(num_layers, num_classes)\n",
        "network = network.cuda()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63df2fe7ac224957b87c2d5bff20e81e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0baf83c96a2741f5bbda6cdc5056a379",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RviaF6bLjxG"
      },
      "source": [
        "optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7, patience=2, verbose=True, mode='max')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "3-MX7YxyLwvB",
        "outputId": "eec86ef5-e5ce-4621-9d84-ce0555ac80de"
      },
      "source": [
        "train(directory, network, loss_fn, train_dataset, val_dataset, optimizer, scheduler, batch_size, num_epochs)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 335/335 [00:13<00:00, 24.48it/s]\n",
            "  0%|          | 1/3022 [00:00<08:59,  5.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  0, test_loss: 0.093335, test_acc: 0.00047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:41<00:00,  7.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.031963, train_acc:0.746566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:42<00:00,  7.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.014974, train_acc:0.879298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:41<00:00,  7.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.012851, train_acc:0.888928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:42<00:00,  7.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.011471, train_acc:0.895920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/3022 [00:00<06:48,  7.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch     4: reducing learning rate of group 0 to 7.0000e-06.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:42<00:00,  7.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.010109, train_acc:0.905809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 335/335 [00:13<00:00, 24.60it/s]\n",
            "  0%|          | 1/3022 [00:00<06:58,  7.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  5, test_loss: 0.012866, test_acc: 0.88067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:41<00:00,  7.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.009207, train_acc:0.912957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:39<00:00,  7.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.008374, train_acc:0.919060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:38<00:00,  7.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.007648, train_acc:0.925204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:40<00:00,  7.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.007006, train_acc:0.931038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/3022 [00:00<06:48,  7.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch     9: reducing learning rate of group 0 to 4.9000e-06.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [06:40<00:00,  7.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss:0.006229, train_acc:0.939189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 335/335 [00:13<00:00, 24.59it/s]\n",
            "  0%|          | 1/3022 [00:00<07:00,  7.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 10, test_loss: 0.014961, test_acc: 0.87721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▎        | 415/3022 [00:54<05:44,  7.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-9ae0409c503f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-8d2de4b6b8a9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(directory, network, loss_fn, train_dataset, test_dataset, optimizer, scheduler, batch_size, num_epochs, verbose, val_freq)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#loss = output.loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVx8jDifcJfH"
      },
      "source": [
        "Get the tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYXc9V4Zb0DO",
        "outputId": "e4d2ae39-cb7d-4844-f690-37773dcc8305"
      },
      "source": [
        "network = BertBiLSTM(num_layers, num_classes)\n",
        "network.load_state_dict(torch.load(f\"{directory}/snapshot_val_best\"))\n",
        "network.cuda()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertBiLSTM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): BiLSTM(\n",
              "    (lstm): LSTM(768, 128, num_layers=2, bidirectional=True)\n",
              "    (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (fc2): Linear(in_features=128, out_features=19, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS0-yqcUlvEu"
      },
      "source": [
        "Inference and save preds / logits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkjFRWcSc_xC"
      },
      "source": [
        "\n",
        "def get_labels(tsv_file):\n",
        "  index2label, label2index = None, None\n",
        "  tsv_file = open(tsv_file)\n",
        "  read_tsv = csv.reader(tsv_file)\n",
        "  labels = [row[0] for row in read_tsv]\n",
        "  if label2index is None:\n",
        "    label_set = set(labels)\n",
        "    label2index = {label:index for index, label in enumerate(label_set)}\n",
        "    index2label = {index:label for index, label in enumerate(label_set)}\n",
        "  return label2index, index2label\n",
        "  "
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y81GrgqNebhm",
        "outputId": "5bcd18af-257a-441c-fba4-ce87830ce6b6"
      },
      "source": [
        "tr_tags = \"/content/drive/MyDrive/NQ/data/answer_tags/train_soft_tag.tsv\"\n",
        "val_tags = \"/content/drive/MyDrive/NQ/data/answer_tags/dev_soft_tag.tsv\"\n",
        "tr_i2l, tr_l2i = get_labels(tr_tags)\n",
        "print(tr_i2l)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LANGUAGE': 0, 'WORK_OF_ART': 1, 'EVENT': 2, 'GPE': 3, 'PERCENT': 4, 'FAC': 5, 'ORG': 6, 'ORDINAL': 7, 'TIME': 8, 'NORP': 9, 'MONEY': 10, 'LOC': 11, 'LAW': 12, 'PRODUCT': 13, 'PERSON': 14, 'DATE': 15, 'OTHERS': 16, 'QUANTITY': 17, 'CARDINAL': 18}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDAcSOpbcLYB"
      },
      "source": [
        "def inference(network, dataset, batch_size):\n",
        "  logits = []\n",
        "  preds = []\n",
        "  loader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
        "  network.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, (input_ids, masks, labels) in tqdm(enumerate(loader),total=len(loader),position=0, leave=True):\n",
        "      input_ids = input_ids.cuda()\n",
        "      masks = masks.cuda()\n",
        "      labels = labels.cuda()\n",
        "            \n",
        "      output = network(input_ids, masks)\n",
        "      logits.append(output)\n",
        "      pred = torch.argmax(output,dim=1)\n",
        "      preds.extend([tr_l2i[pred[i].item()] for i in range(len(pred))])\n",
        "      #output = network(input_ids, masks, labels=labels)\n",
        "      #preds = torch.argmax(output.logits, dim=1)\n",
        "      #loss = output.loss\n",
        "\n",
        "    \n",
        "  return torch.cat(logits), preds"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmiBSbu4fA2H",
        "outputId": "d35b47c9-da6c-49aa-e8ef-9897d1375d68"
      },
      "source": [
        "val_logits, val_preds = inference(network, val_dataset, 32)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 335/335 [00:13<00:00, 24.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmcYDxsdjxBB",
        "outputId": "fcef8dbc-17bf-442d-ec29-9389581e98f5"
      },
      "source": [
        "tr_logits, tr_preds = inference(network, train_dataset, 32)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3022/3022 [02:03<00:00, 24.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4zE1-NfhN_C"
      },
      "source": [
        "torch.save(val_logits, f\"{directory}/val_logits\")"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w48X-NDPhVfp"
      },
      "source": [
        "torch.save(tr_logits, f\"{directory}/tr_logits\")"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFJGCRqXlJvl"
      },
      "source": [
        "with open(f\"{directory}/val_preds.tsv\", 'w') as v_f:\n",
        "  v_f.write('\\n'.join(val_preds))"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcrYnqojliP2"
      },
      "source": [
        "with open(f\"{directory}/tr_preds.tsv\", 'w') as t_f:\n",
        "  t_f.write('\\n'.join(tr_preds))"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_BZ2CVMmTfl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}