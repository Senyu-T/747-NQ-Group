{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BART_NQ.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "90KgHF6XkOw9"
      },
      "source": [
        "!pip install torch==1.1.0\n",
        "!pip install git+https://github.com/huggingface/transformers.git@7b75aa9fa55bee577e2c7403301ed31103125a35"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGUkMDujkUtz"
      },
      "source": [
        "!git clone https://github.com/Senyu-T/unifiedqa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNlgBI9fGn4X",
        "outputId": "9dbc5dbb-eb2a-4487-a42e-f69b66b408cf"
      },
      "source": [
        "cd unifiedqa/bart"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/unifiedqa/bart\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sC-SOiOGqkn",
        "outputId": "10df31d0-6858-45fc-c019-d590e6b5836a"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bart.py  data.py            README.md  unified_data.py\n",
            "\u001b[0m\u001b[01;32mcli.py\u001b[0m*  \u001b[01;32mdownload_data.sh\u001b[0m*  run.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeGQOSHLk9Pw"
      },
      "source": [
        "!chmod +x download_data.sh; ./download_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFBiJ-TZDFch",
        "outputId": "c431398d-598a-495a-e137-7bc276c19608"
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bart.py  \u001b[0m\u001b[01;34mdata\u001b[0m/    \u001b[01;32mdownload_data.sh\u001b[0m*  run.py\n",
            "\u001b[01;32mcli.py\u001b[0m*  data.py  README.md          unified_data.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvVnvqgAv4Zo",
        "outputId": "1a58ed9d-99e9-43a8-e851-3ad33fc1354e"
      },
      "source": [
        "!python cli.py --do_train --output_dir out/finetune_bart_base_2_epoch \\\n",
        "    --train_file data/natural_questions_with_dpr_para/train.tsv \\\n",
        "    --predict_file data/natural_questions_with_dpr_para/dev.tsv \\\n",
        "    --train_batch_size 16\\\n",
        "    --predict_batch_size 16\\\n",
        "    --append_another_bos --do_lowercase --num_train_epochs 2 --verbose"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-15 03:02:24.959688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "04/15/2021 03:02:27 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=True, checkpoint=None, checkpoint_step=0, debug=False, do_lowercase=True, do_predict=False, do_train=True, eval_period=2000, gradient_accumulation_steps=1, is_unifiedqa=False, learning_rate=1e-05, max_grad_norm=1.0, max_input_length=512, max_output_length=100, num_beams=4, num_train_epochs=2.0, output_dir='out/finetune_bart_base_2_epoch', predict_batch_size=16, predict_file='data/natural_questions_with_dpr_para/dev.tsv', prefix='', seed=42, skip_inference=False, train_batch_size=16, train_file='data/natural_questions_with_dpr_para/train.tsv', verbose=True, wait_step=10, warmup_proportion=0.01, warmup_steps=0, weight_decay=0.0)\n",
            "04/15/2021 03:02:27 - INFO - __main__ - out/finetune_bart_base_2_epoch\n",
            "04/15/2021 03:02:27 - INFO - __main__ - Using 1 gpus\n",
            "04/15/2021 03:02:27 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/15/2021 03:02:27 - INFO - filelock - Lock 140464614355024 acquired on /root/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n",
            "04/15/2021 03:02:27 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpjj59gcmy\n",
            "Downloading: 100% 899k/899k [00:00<00:00, 1.76MB/s]\n",
            "04/15/2021 03:02:28 - INFO - transformers.file_utils - storing https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json in cache at /root/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "04/15/2021 03:02:28 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "04/15/2021 03:02:28 - INFO - filelock - Lock 140464614355024 released on /root/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n",
            "04/15/2021 03:02:28 - INFO - filelock - Lock 140464752434512 acquired on /root/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "04/15/2021 03:02:28 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmprrtddm2m\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 1.33MB/s]\n",
            "04/15/2021 03:02:29 - INFO - transformers.file_utils - storing https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt in cache at /root/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "04/15/2021 03:02:29 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "04/15/2021 03:02:29 - INFO - filelock - Lock 140464752434512 released on /root/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "04/15/2021 03:02:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /root/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "04/15/2021 03:02:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /root/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "04/15/2021 03:02:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None\n",
            "04/15/2021 03:02:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None\n",
            "04/15/2021 03:02:30 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None\n",
            "Start tokenizing...\n",
            "04/15/2021 03:03:10 - INFO - __main__ - Loaded 10693 examples from dev data\n",
            "Start tokenizing...\n",
            "04/15/2021 03:08:45 - INFO - __main__ - Loaded 96676 examples from train data\n",
            "04/15/2021 03:08:49 - INFO - filelock - Lock 140464506101328 acquired on /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb.lock\n",
            "04/15/2021 03:08:49 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpvqr9d9ys\n",
            "Downloading: 100% 1.55k/1.55k [00:00<00:00, 1.31MB/s]\n",
            "04/15/2021 03:08:49 - INFO - transformers.file_utils - storing https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json in cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n",
            "04/15/2021 03:08:49 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n",
            "04/15/2021 03:08:49 - INFO - filelock - Lock 140464506101328 released on /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb.lock\n",
            "04/15/2021 03:08:49 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n",
            "04/15/2021 03:08:49 - INFO - transformers.configuration_utils - Model config BartConfig {\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\",\n",
            "    \"BartForConditionalGeneration\",\n",
            "    \"BartForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 128,\n",
            "      \"min_length\": 12,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_cnn\": {\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 62,\n",
            "      \"min_length\": 11,\n",
            "      \"num_beams\": 6\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "04/15/2021 03:08:50 - INFO - filelock - Lock 140464189990800 acquired on /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c.lock\n",
            "04/15/2021 03:08:50 - INFO - transformers.file_utils - https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpc3a54o3f\n",
            "Downloading: 100% 558M/558M [00:19<00:00, 28.4MB/s]\n",
            "04/15/2021 03:09:10 - INFO - transformers.file_utils - storing https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin in cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n",
            "04/15/2021 03:09:10 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n",
            "04/15/2021 03:09:10 - INFO - filelock - Lock 140464189990800 released on /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c.lock\n",
            "04/15/2021 03:09:10 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n",
            "04/15/2021 03:09:16 - INFO - __main__ - Starting training!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "100% 669/669 [07:22<00:00,  1.51it/s]\n",
            "04/15/2021 03:30:59 - INFO - __main__ - Step 2000 Train loss 124.60 EM 27.25% on epoch=0\n",
            "04/15/2021 03:31:01 - INFO - __main__ - Saving model with best EM: -100.00% -> 27.25% on epoch=0, global_step=2000\n",
            "100% 669/669 [07:22<00:00,  1.51it/s]\n",
            "04/15/2021 03:52:44 - INFO - __main__ - Step 4000 Train loss 106.07 EM 29.34% on epoch=0\n",
            "04/15/2021 03:52:46 - INFO - __main__ - Saving model with best EM: 27.25% -> 29.34% on epoch=0, global_step=4000\n",
            "100% 669/669 [07:19<00:00,  1.52it/s]\n",
            "04/15/2021 04:14:26 - INFO - __main__ - Step 6000 Train loss 103.57 EM 29.34% on epoch=0\n",
            "100% 669/669 [07:15<00:00,  1.54it/s]\n",
            "04/15/2021 04:36:01 - INFO - __main__ - Step 8000 Train loss 91.81 EM 29.12% on epoch=1\n",
            "100% 669/669 [07:20<00:00,  1.52it/s]\n",
            "04/15/2021 04:57:42 - INFO - __main__ - Step 10000 Train loss 91.60 EM 30.29% on epoch=1\n",
            "04/15/2021 04:57:44 - INFO - __main__ - Saving model with best EM: 29.34% -> 30.29% on epoch=1, global_step=10000\n",
            "100% 669/669 [07:21<00:00,  1.51it/s]\n",
            "04/15/2021 05:19:27 - INFO - __main__ - Step 12000 Train loss 90.64 EM 30.22% on epoch=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuzI8Be_dOQF",
        "outputId": "64ff06b0-0dec-470e-a6cd-784a1319f803"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNwMP--_FsBg"
      },
      "source": [
        "cp -r out ../../drive/MyDrive"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9JheQ4BHih2",
        "outputId": "f4bc71d5-d266-49e9-8528-a77b02375c2f"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-8cc1ac53-77a9-9d54-5e19-5f8428ce32c8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PinDt0cmIGIq",
        "outputId": "ab407b1b-736c-433c-e898-8fd890a7a3e3"
      },
      "source": [
        "!python cli.py --do_predict --output_dir out/finetune_bart_base_2_epoch \\\n",
        "    --predict_file data/natural_questions_with_dpr_para/dev.tsv \\\n",
        "    --predict_batch_size 16\\\n",
        "    --append_another_bos"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-15 06:05:20.271987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Output directory () already exists and is not empty.\n",
            "04/15/2021 06:05:22 - INFO - __main__ - Namespace(adam_epsilon=1e-08, append_another_bos=True, checkpoint=None, checkpoint_step=0, debug=False, do_lowercase=False, do_predict=True, do_train=False, eval_period=2000, gradient_accumulation_steps=1, is_unifiedqa=False, learning_rate=1e-05, max_grad_norm=1.0, max_input_length=512, max_output_length=100, num_beams=4, num_train_epochs=10000.0, output_dir='out/finetune_bart_base_2_epoch', predict_batch_size=16, predict_file='data/natural_questions_with_dpr_para/dev.tsv', prefix='', seed=42, skip_inference=False, train_batch_size=40, train_file='data/train.tsv', verbose=False, wait_step=10, warmup_proportion=0.01, warmup_steps=0, weight_decay=0.0)\n",
            "04/15/2021 06:05:22 - INFO - __main__ - out/finetune_bart_base_2_epoch\n",
            "04/15/2021 06:05:22 - INFO - __main__ - Using 1 gpus\n",
            "04/15/2021 06:05:22 - INFO - transformers.tokenization_utils - Model name 'facebook/bart-base' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-base' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/15/2021 06:05:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/vocab.json from cache at /root/.cache/torch/transformers/7a7fc1746df9ea150ffd06a23351e5854c2105db3a0be1e0307dfd74fbf4a65c.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "04/15/2021 06:05:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/merges.txt from cache at /root/.cache/torch/transformers/3d0d1735635ef097afbf08cf5af21618c94286b8e8b53cfb9bd6cdcfc91d4e14.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "04/15/2021 06:05:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/added_tokens.json from cache at None\n",
            "04/15/2021 06:05:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/special_tokens_map.json from cache at None\n",
            "04/15/2021 06:05:23 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/tokenizer_config.json from cache at None\n",
            "Start tokenizing...\n",
            "04/15/2021 06:06:04 - INFO - __main__ - Loaded 10693 examples from dev data\n",
            "04/15/2021 06:06:05 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-base/config.json from cache at /root/.cache/torch/transformers/09f4fcaeaf785dd3b97b085d6e3510c7081f586ec8e75981683c6299c0f81d9d.e8d516ad807436d395effad8c2326786872659b7dd1210827ac67c761198a0eb\n",
            "04/15/2021 06:06:05 - INFO - transformers.configuration_utils - Model config BartConfig {\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\",\n",
            "    \"BartForConditionalGeneration\",\n",
            "    \"BartForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 128,\n",
            "      \"min_length\": 12,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_cnn\": {\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 62,\n",
            "      \"min_length\": 11,\n",
            "      \"num_beams\": 6\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "04/15/2021 06:06:05 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/facebook/bart-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/566c05fb6983817e8ad7a4fa51e3099fe9caa3b31730f964bc5198d71c677523.0a3d95c18c1e434448941bc25accea7b122882be6526fb67c8e8fb6d5ebc711c\n",
            "04/15/2021 06:06:09 - INFO - __main__ - Loading checkpoint from out/finetune_bart_base_2_epoch/best-model.pt\n",
            "04/15/2021 06:13:36 - INFO - __main__ - Saved prediction in out/finetune_bart_base_2_epoch/predictions.json\n",
            "04/15/2021 06:13:37 - INFO - __main__ - EM on dev data: 30.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z26y5ojklYQM"
      },
      "source": [
        "Now we have the model output. We also find that the \"nq-dev\" set provided by DPR is a subset of current dev set, so in order to reproduce results in unitedQA we'll use the dev set in this repo which contains 10000 questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR2dRV6VawV8",
        "outputId": "f2175060-c325-4b3e-dbe9-ea37cffb559d"
      },
      "source": [
        "cd /content/unifiedqa/bart/data/natural_questions_with_dpr_para/"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/unifiedqa/bart/data/natural_questions_with_dpr_para\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa26s602l7X9"
      },
      "source": [
        "# read dev file, parse into context / question / answer for further data analysis\n",
        "infer_answers = []\n",
        "infer_questions = []\n",
        "infer_contexts = []\n",
        "with open('dev.tsv', 'rb') as inference_in:\n",
        "    lines = inference_in.readlines()\n",
        "    for i in range(len(lines)):\n",
        "        sep = str(lines[i]).split('\\\\n') \n",
        "        infer_questions.append(sep[0][2:-1])\n",
        "        infer_answers.append((sep[1].split('\\\\t')[-1]).lower())\n",
        "        infer_contexts.append(sep[1].split('\\\\t')[0])\n",
        "\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_lLfMBscmQe",
        "outputId": "0e6d985a-bb89-4074-80fd-4d3ffbb8130c"
      },
      "source": [
        "cd /content/unifiedqa/bart/out/finetune_bart_base_2_epoch"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/unifiedqa/bart/out/finetune_bart_base_2_epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31rlEtXcmGIJ",
        "outputId": "3f266c98-81ee-4fdc-d5af-66c8da4f6b5b"
      },
      "source": [
        "ls"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best-model.pt  eval_log.txt  log.txt  predictions.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRFA3TwomdmZ"
      },
      "source": [
        "# read the prediction file output by model\n",
        "import json\n",
        "with open(\"predictions.json\", 'rb') as m_out:\n",
        "    pred = json.load(m_out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdEJL8evxDtg"
      },
      "source": [
        "# check how many short answers are not extracted from the context\n",
        "not_in_dpr_idx = []\n",
        "for i in range(len(infer_answers)):\n",
        "  if not infer_answers[i] in infer_contexts[i]:\n",
        "    not_in_dpr_idx.append(i)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h241kCe7nTVb",
        "outputId": "37af892e-5593-42c6-cace-dc77fc7c9de4"
      },
      "source": [
        "print(len(infer_answers), len(pred))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10693 10693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfU0jcL51HZB",
        "outputId": "4840dafa-171c-4818-d8cf-f91f55a29ce9"
      },
      "source": [
        "cd /content/unifiedqa/bart"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/unifiedqa/bart\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOysjJG2qyH"
      },
      "source": [
        "def store_file(out_dir, arr):\n",
        "  with open(out_dir, 'w') as f:\n",
        "    f.write(\"\\n\".join(str(arr[i]) for i in range(len(arr))))"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQo_F3om1Pvf"
      },
      "source": [
        "store_file(\"pred.txt\", pred)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp-CoyPe0lfm",
        "outputId": "561e5e46-f188-42f1-9479-ab7498d50a78"
      },
      "source": [
        "# detokenize: restore special marks\n",
        "# also find special token (forien language)\n",
        "cnt_special_char = 0\n",
        "for i in range(len(infer_answers)):\n",
        "  infer_answers[i] = infer_answers[i].replace(' \\\\\\'\\\\\\'', ' \\'\\'')   # double quotation\n",
        "  infer_answers[i] = infer_answers[i].replace('\\\\\\'', '\\'')\n",
        "  infer_answers[i] = infer_answers[i].replace(' \\'s', '\\'s')    # 's\n",
        "  infer_answers[i] = infer_answers[i].replace(' ,', ',')        # comma\n",
        "  if '\\\\' in infer_answers[i]:\n",
        "    cnt_special_char += 1\n",
        "    #print(f\"{i}  {infer_answers[i]}      {pred[i]}\")\n",
        "print(cnt_special_char)\n",
        "\n",
        " "
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3FPHalz3H7V"
      },
      "source": [
        "store_file(\"infer_ans.txt\", infer_answers)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzD5d665EPLz"
      },
      "source": [
        "cp infer_ans.txt /content/drive/MyDrive"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROMLTQsJnXU1",
        "outputId": "73e7b113-d543-48c6-97bb-940b12466f83"
      },
      "source": [
        "# Evaluate \n",
        "is_correct = 0.0\n",
        "for i in range(len(infer_answers)):\n",
        "  if infer_answers[i] == pred[i]:\n",
        "    #print(pred[i], i)\n",
        "    is_correct += 1\n",
        "\n",
        "print(is_correct / len(infer_answers))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2904704011970448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_YDB0uH22m",
        "outputId": "11ba8710-31cc-41b0-e335-f0908808e31a"
      },
      "source": [
        "print(is_correct / (len(infer_answers) - cnt_special_char))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2937671427220278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3dkRrnfIT-h"
      },
      "source": [
        "with open(\"error.txt\", \"w\") as f:\n",
        "  for i in range(len(infer_answers)):\n",
        "    if infer_answers[i] != pred[i]:\n",
        "      f.write(f\"{i}: {infer_answers[i]:30s}{pred[i]}\\n\")"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymp-VTkqI45l"
      },
      "source": [
        "cp error.txt /content/drive/MyDrive"
      ],
      "execution_count": 167,
      "outputs": []
    }
  ]
}